{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Explorative Datenanalyse: Das Beste kommt zum Schluss</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Willkommen bei der dritten praktischen Übung zum Thema explorative Datenanalyse! Wir befinden uns bereits in unserer letzten Übung. Nachdem wir uns in den beiden vorhergehenden Übungen mit den Grundlagen des Datenverständnisses auseinander gesetzt haben, wollen wir mit dieser Übung etwas tiefer in die explorative Analyse einsteigen. Konkret verfolgen wir mit dieser Übung folgende Lernziele:\n",
    "\n",
    "- Sie sollen lernen, wie Sie die Qualität eines Datensatzes einschätzen können.\n",
    "- Sie sollen über Suchmaschinen oder Dokumentationen Antworten auf Implementierungsfragen finden können.\n",
    "\n",
    "Voraussichtlich werden Sie für diese Übung maximal 0:45h benötigen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Datenqualität</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Einschätzung der Datenqualität ist ein zentrales Ziel der explorativen Datenanalyse. Sie wissen bereits, dass Daten möglichst relevant, repräsentativ, vollständig und fehlerfrei sein sollten. Die Relevanz von Merkmalen kann man als Außenstehender ohne Expertenwissen leider nur schwer einschätzen (im Skript finden Sie aber auch zwei Gegenbeispiele). Die Repräsentativität eines Datensatzes kann man gut über Häufigkeitsverteilungen (also Säulen- oder Balkendiagramme und Histogramme) beurteilen, indem man zum Beispiel schaut, ob es eine vergleichbare Anzahl an Datenpunkten für bestimmte Gruppen gibt (zum Beispiel Männer und Frauen). In der ersten Übung haben wir uns außerdem angesehen, welche Merkmale und viele Datenpunkte es insgesamt in unserem Datensatz gibt sowie ob uns fehlende Werte auffallen (mit pandas' ```head()```- und ```describe()```-Funktionen). Damit können wir die Vollständigkeit des Datensatzes gut abschätzen. Wir haben zudem bereits Fehler bei der Zuweisung der Merkmalstypen korrigiert. Weitere Fehler kann man bei der Betrachung von Häufigkeitsverteilungen, vor allem der Ausreißer, als auch der Lage- und Streuungsmaße ausmachen. Ein Beispiel aus der ersten Übung war ein Produkt einer Kategorie, die nicht in der Dokumentation auftaucht (Kategorie ```Z```). Um an dieser Stelle noch einmal einen schnellen Überblick über die Datenqualität zu erhalten, lassen wir uns noch einmal die Merkmale und deren Typen, die Anzahl der Datenpunkte sowie fehlende Werte in unserem Datensatz anzeigen. Dazu können wir pandas' ```info()```-Funktion benutzen. Zuvor bereiten wir unseren Datensatz natürlich entsprechend vor, wie wir es bereits aus der ersten Übung kennen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "data = pd.read_csv(\"../data_sets/mechatronic_systems/data.csv\", delimiter=\";\", decimal=\",\")\n",
    "\n",
    "data[\"Maschine\"] = pd.Categorical(data[\"Maschine\"])\n",
    "data[\"Produkt\"] = pd.Categorical(data[\"Produkt\"])\n",
    "data[\"Mode\"] = pd.Categorical(data[\"Mode\"], ordered=True)\n",
    "\n",
    "exploration_data = data.sample(frac=0.75, random_state=42)\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können erkennen, dass nicht jedes Merkmal über 1000 Datenpunkte verfügt, es gibt also einige fehlende Werte. Wir sehen aber auch, dass wir unseren Merkmalen ```Maschine```, ```Mode``` und ```Produkt``` richtigerweise einen kategoriellen Datentyp zugewiesen haben. Eine weitere wichtige Fehlerquelle, die wir bisher nicht betrachtet haben, sind Duplikate. pandas bietet die Möglichkeit, sowohl Duplikate über alle Merkmale hinweg zu finden (also wenn sich eine ganze Zeile der Tabelle doppelt) als auch über einzelne Merkmale hinweg (also wenn sich ein einzelner Wert in einer Spalte der Tabelle doppelt). Dazu können wir die ```duplicated()```-Funktion verwenden. Diese gibt für jede Zeile der Tabelle einen Boolean aus: ```0```, wenn es keine Dopplungen gibt, und ```1```, wenn es Dopplungen gibt. Wenn wir also die Ausgabe dieser Funktion summieren und der Wert ```0``` herauskommt, wissen wir, dass sich in unserer gesamten Tabelle keine Zeile doppelt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gute Nachrichten, in unserem Datensatz kommt schon einmal keine komplette Zeile doppelt vor! Wir können uns nun noch beispielhaft anschauen, ob sich einzelne Werte in einer Spalte der Tabelle doppeln. Ein solcher Test ergibt natürlich vor allem bei Floats Sinn - dass sich Kategorien oder Integers doppeln, ist immerhin zu erwarten. Wir geben der ```duplicated()```-Funktion das Merkmal ```Strom / A``` als String mit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data.duplicated(\"Strom / A\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es werden also 67 Werte gefunden, die bei unserem Merkmal ```Strom / A``` doppelt vorkommen. Ob das bei einem Datensatz von 1000 Datenpunkten zu erwarten ist, ist kontextabhängig. Ein erneuter Blick auf unsere [Daten](../data_sets/mechatronic_systems/data.csv) vorrät uns, dass wir drei Nachkommastellen bei der Stromaufnahme berücksichtigen. Damit ist es nicht unwahrscheinlich, dass eine gewisse Anzahl an Werten doppelt vorkommen kann - bei einer größeren Anzahl an Nachkommastellen würde man weniger Duplikate erwarten. Bei Interesse können Sie die Daten noch einmal genauer studieren, um zu sehen, ob die Duplikate zum Beispiel gehäuft untereinander stehen und so auf Falscheintragungen hinweisen könnten. Insgesamt sollte Ihnen aber aufgefallen sein, dass wir zur Einschätzung der Datenqualität zum Großteil auf bewährte Methoden aus der ersten praktischen Übung zurückgreifen konnten - wir haben lediglich die Suche nach Duplikaten neu eingeführt und können damit nun die Datenqualität relativ umfassend beurteilen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Wer suchet, der findet</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachdem Sie in dieser Übung bisher nur vorgefertigten Code ausgeführt haben, wird es nun Zeit, dass Sie wieder selbst aktiv werden. Dies hat einen guten Grund: Zwar helfen Ihnen vorgefertigte Codeblöcke dabei, die Grundlagen der explorativen Datenanalyse schnell zu erlernen; da man bei der Programmierung aber meist auf bestehende Bibliotheken zurückgreift, wird in der Praxis oft eine erhebliche Zeit dafür benötigt, die passenden Funktionen einer Bibliothek für ein bestimmtes Ziel herauszufinden, Funktionsargumente zu verstehen und nach Bedarf anzupassen, Probleme zu beheben usw. Es ist sogar sehr gut möglich, dass Sie später für Ihre explorative Analyse gar nicht pandas und Plotly verwenden werden, sondern ganz andere Bibliotheken oder gar Programmiersprachen. Daher ist es extrem wichtig, dass Sie auch lernen, Funktionalitäten von Bibliotheken zu benutzen, die Ihnen bisher unbekannt sind. Und genau das wollen wir nun an dieser Stelle üben: Stellen Sie sich dazu vor, dass Sie die Zusammenhänge zwischen Ihren Merkmalen mit dem Korrelationskoeffizienten nach Pearson quantifiziert und in einer Heatmap dargestellt haben (genauso wie in der ersten Übung). Allerdings scheinen sich einige der Korrelationen nicht mit Ihren Erkenntnissen aus den Streudiagrammen zu decken. Dabei erinnern Sie sich, dass Ihnen in einigen Streudiagrammen deutliche Ausreißer aufgefallen sind. Suchen Sie daher (über Suchmaschinen oder Dokumentationen) einen Korrelationskoeffizienten, der robuster gegen Ausreißer ist, und stellen Sie eine Heatmap mit diesem Korrelationskoeffizienten für den Explorationsdatensatz dar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Zusammenfassung</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir hoffen, dass wir Ihnen mit dieser Übung fortgeschrittenere Konzepte der explorativen Datenanalyse gut näherbringen konnten. Sie haben erfahren, wie Sie Ihr Wissen aus der ersten praktischen Übung zusammen mit pandas' ```duplicated()```-Funktion nutzen können, um abschätzen, wie repräsentativ, vollständig und fehlerfrei ein vorliegender Datensatz ist. Zudem haben Sie sich selbst eine Antwort auf eine praktische Implementierungsfrage erarbeitet. Damit haben Sie nun einige Werkzeuge an der Hand, um eigenständig Daten explorativ zu analysieren und für Ihre Entscheidungen nutzen zu können. Wir wünschen Ihnen viel Erfolg und vor allem viel Spaß bei der Erkundung von Daten!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b07170ffe031b9291924a8d255d526a1b93401860d2b821f7b92d48f2ffde530"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
